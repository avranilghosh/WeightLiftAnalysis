---
title: "Analysis of Pattern in Weight Lifting Exercise"
author: "Avranil Ghosh"
date: "Sunday, March 22, 2015"
output: html_document
---

## Executive Sumary:

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively 
inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to 
improve their health, to find patterns in their behavior.

In this Report we will try to analyze the pattern in which barbell lifts were performed correctly/incorrectly in 5 different ways using data from 
accelerometers on the belt, forearm, arm, and dumbell of 6 participants.

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har


### Loading data and cleaning

```{r dataload,echo=FALSE,cache=TRUE}
test<-read.csv("pml-testing.csv")
train<-read.csv("pml-training.csv")
name<-names(train)

```

We load the training and testing data from the source into train and test data frames. We further clean up the data to remove the columns with no values or 
NA. We also delete the first column which stores only the row id. The cleaned dataset in train and test variables have 56 columns mentioned below:

`r name`

### Performing Data split

```{r split,echo=FALSE,cache=TRUE}

library(caret)
set.seed(32323)

folds<-createFolds(y=train$classe,k=3,list=TRUE,returnTrain=TRUE)

train1<-train[folds[[1]],]
test1<-train[-folds[[1]],]

train2<-train[folds[[2]],]
test2<-train[-folds[[2]],]

train3<-train[folds[[3]],]
test3<-train[-folds[[3]],]

dtrain1<-dim(train1)
dtest1<-dim(test1)

```

We perform K means clustering with k=3. Each fold has train and test data sets with the dimensions:

`r dtrain1`

`r dtest1`

### ModelFitting

We generate a model using random Forest on each of the train datasets generated from k fold. The model on first train dataset looks like:

```{r modelfit,echo=FALSE,cache=TRUE}

library(randomForest)
set.seed(32323)
model1<-randomForest(classe~.,data=train1[1:56])
pred1<-predict(model1,test1[1:55])
tab<-table(test1$classe,pred1)
model2<-randomForest(classe~.,data=train2[1:56])
pred2<-predict(model2,test2[1:55])
tab2<-table(test2$classe,pred2)
model3<-randomForest(classe~.,data=train3[1:56])
pred3<-predict(model3,test3[1:55])
tab3<-table(test3$classe,pred3)

```

```{r modelout1,echo=FALSE,cache=TRUE}
print(model1)

```



As we can see from the confusion Matix, the error rate is quite low = 0.34%.

We use the above model to predict classe values for the first test data set and  plot the predicted values against the actual classe values:

`r tab`

We can see 19 cases out of 6541 total test values where there is mismatch. This gives misclassification error of 0.003 which shows that our model predicts 
quite well.

We expect the same error rate when we use this model on the other test data sets generated using k fold. 




The model on second train dataset looks like:

```{r modelout2,echo=FALSE,cache=TRUE}
print(model2)

```

As we can see from the confusion Matix, the error rate is quite low = 0.32%.

We use the above model to predict classe values for the first test data set and  plot the predicted values against the actual classe values:

`r tab2`

We can see 17 cases out of 6541 total test values where there is mismatch. This gives misclassification error of 0.003 which shows that our model predicts 
quite well.




The model on third train dataset looks like:

```{r modelout3,echo=FALSE,cache=TRUE}
print(model3)

```

As we can see from the confusion Matix, the error rate is quite low = 0.28%.

We use the above model to predict classe values for the first test data set and  plot the predicted values against the actual classe values:

`r tab3`

We can see 24 cases out of 6541 total test values where there is mismatch. This gives misclassification error of 0.004 which shows that our model predicts 
quite well.

Out of the 3 models generated above, all have very less misclasification error. Since the second model has the least mismatch cases, we proceed with our final prediction with the second model.



### Predicting Output

We use the above model to predict the output in the actual test data set:

```{r predictout,echo=FALSE,cache=TRUE}

testing1<-rbind(test[1:55],test1[1:55])
pred1f<-predict(model2,testing1)
out<-pred1f[1:20]


```

The predicted classe for the 20 test cases comes out correctly to be:

`r out`